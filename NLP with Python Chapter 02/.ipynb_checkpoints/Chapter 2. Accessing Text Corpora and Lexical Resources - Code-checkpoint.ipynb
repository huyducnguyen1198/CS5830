{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b298ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d89b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "len(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))\n",
    "emma.concordance(\"surprize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124fcb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileid in gutenberg.fileids():\n",
    "    num_chars = len(gutenberg.raw(fileid))\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "    num_vocab = len(set([w.lower() for w in gutenberg.words(fileid)]))\n",
    "    print(int(num_chars/num_words), int(num_words/num_sents), int(num_words/num_vocab), fileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64007cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_sentences = gutenberg.sents('shakespeare-macbeth.txt')\n",
    "macbeth_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_sentences[1037]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca8565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_len = max([len(s) for s in macbeth_sentences])\n",
    "longest_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in macbeth_sentences if len(s) == longest_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e37d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import webtext\n",
    "for fileid in webtext.fileids():\n",
    "    print(fileid, webtext.raw(fileid)[:65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b670b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import nps_chat\n",
    "chatroom = nps_chat.posts('10-19-20s_706posts.xml')\n",
    "chatroom[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d6691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b8557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "brown.words(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049bdbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "brown.words(fileids=['cg22'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9bc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "brown.sents(categories=['news', 'editorial', 'reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df993f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "news_text = brown.words(categories='news')\n",
    "fdist = nltk.FreqDist([w.lower() for w in news_text])\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30971f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "for m in modals:\n",
    "    print(m + ':', fdist[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e200b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist( (genre, word) for genre in brown.categories() for word in brown.words(categories=genre))\n",
    "cfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0adf25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "cfd.tabulate(conditions=genres, samples=modals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcaa472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "reuters.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c1a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.categories('training/9865')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.categories(['training/9865', 'training/9880'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3385c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.fileids('barley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a9a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.fileids(['barley', 'corn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb494b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.words('training/9865')[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9bc425",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.words(['training/9865', 'training/9880'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.words(categories='barley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b481ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.words(categories=['barley', 'corn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a83aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import inaugural\n",
    "inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d49f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[fileid[:4] for fileid in inaugural.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef42dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "(target, fileid[:4])\n",
    "for fileid in inaugural.fileids()\n",
    "for w in inaugural.words(fileid)\n",
    "for target in ['america', 'citizen']\n",
    "if w.lower().startswith(target))\n",
    "\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.cess_esp.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c40c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.floresta.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42158097",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.indian.words('hindi.pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14572e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.udhr.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45636025",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.udhr.words('Javanese-Latin1')[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e34288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import udhr\n",
    "languages = ['Chickasaw', 'English', 'German_Deutsch', 'Greenlandic_Inuktikut', 'Hungarian_Magyar', 'Ibibio_Efik']\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (lang, len(word))\n",
    "    for lang in languages\n",
    "    for word in udhr.words(lang + '-Latin1'))\n",
    "\n",
    "cfd.plot(cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0914713",
   "metadata": {},
   "outputs": [],
   "source": [
    "udhr.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e542c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = udhr.raw('Balinese-Latin1')\n",
    "nltk.FreqDist(raw_text).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618d9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = gutenberg.raw(\"burgess-busterbrown.txt\")\n",
    "raw[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f2284",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = gutenberg.words(\"burgess-busterbrown.txt\")\n",
    "words[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25868385",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = gutenberg.sents(\"burgess-busterbrown.txt\")\n",
    "sents[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d411c43",
   "metadata": {},
   "source": [
    "### Loading Your Own Corpus\n",
    "\n",
    "If you have a your own collection of text files that you would like to access using the methods discussed earlier, you can easily load them with the help of NLTK’s PlaintextCorpusReader. Check the location of your files on your file system; in the following example, we have taken this to be the directory /usr/share/dict. Whatever the location, set this to be the value of corpus_root 1. The second parameter of the PlaintextCorpusReader initializer 2 can be a list of fileids, like ['a.txt', 'test/b.txt'], or a pattern that matches all fileids, like '[abc]/.*\\.txt' (see Regular Expressions for Detecting Word Patterns for information about regular expressions).\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    ">>> from nltk.corpus import PlaintextCorpusReader<br>\n",
    ">>> corpus_root = '/usr/share/dict'<br>\n",
    ">>> wordlists = PlaintextCorpusReader(corpus_root, '.*')<br>\n",
    ">>> wordlists.fileids()<br>\n",
    "['README', 'connectives', 'propernames', 'web2', 'web2a', 'words']<br>\n",
    ">>> wordlists.words('connectives')<br>\n",
    "['the', 'of', 'and', 'to', 'a', 'in', 'that', 'is', ...]<br>\n",
    "    </div>\n",
    "\n",
    "As another example, suppose you have your own local copy of Penn Treebank (release 3), in C:\\corpora. We can use the BracketParseCorpusReader to access this corpus. We specify the corpus_root to be the location of the parsed Wall Street Journal component of the corpus 1, and give a file_pattern that matches the files contained within its subfolders 2 (using forward slashes).\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">    \n",
    ">>> from nltk.corpus import BracketParseCorpusReader<br>\n",
    ">>> corpus_root = r\"C:\\corpora\\penntreebank\\parsed\\mrg\\wsj\"<br>\n",
    ">>> file_pattern = r\".*/wsj_.*\\.mrg\"<br>\n",
    ">>> ptb = BracketParseCorpusReader(corpus_root, file_pattern)<br>\n",
    ">>> ptb.fileids()<br>\n",
    "['00/wsj_0001.mrg', '00/wsj_0002.mrg', '00/wsj_0003.mrg', '00/wsj_0004.mrg', ...]<br>\n",
    ">>> len(ptb.sents())<br>\n",
    "49208<br>\n",
    ">>> ptb.sents(fileids='20/wsj_2013.mrg')[19]<br>\n",
    "['The', '55-year-old', 'Mr.', 'Noriega', 'is', \"n't\", 'as', 'smooth', 'as', 'the',\n",
    "'shah', 'of', 'Iran', ',', 'as', 'well-born', 'as', 'Nicaragua', \"'s\", 'Anastasio',<br>\n",
    "'Somoza', ',', 'as', 'imperial', 'as', 'Ferdinand', 'Marcos', 'of', 'the', 'Philippines',\n",
    "'or', 'as', 'bloody', 'as', 'Haiti', \"'s\", 'Baby', Doc', 'Duvalier', '<br>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36be3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#practice loading here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df92790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "cfd = nltk.ConditionalFreqDist((genre, word)\n",
    "    for genre in brown.categories()\n",
    "    for word in brown.words(categories=genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5723683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_word = [(genre, word)\n",
    "    for genre in ['news', 'romance']\n",
    "    for word in brown.words(categories=genre)]\n",
    "\n",
    "len(genre_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9179ce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_word[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda80de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_word[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c647c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(genre_word)\n",
    "cfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be0527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd.conditions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a1de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd['news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafd0e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd['romance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f1b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cfd['romance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb2986",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd['romance']['could']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5674dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import inaugural\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (target, fileid[:4])\n",
    "    for fileid in inaugural.fileids()\n",
    "    for w in inaugural.words(fileid)\n",
    "    for target in ['america', 'citizen']\n",
    "    if w.lower().startswith(target))\n",
    "\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec5eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import udhr\n",
    "languages = ['Chickasaw', 'English', 'German_Deutsch', 'Greenlandic_Inuktikut', 'Hungarian_Magyar', 'Ibibio_Efik']\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (lang, len(word))\n",
    "    for lang in languages\n",
    "    for word in udhr.words('Balinese' + '-Latin1'))\n",
    "\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1549918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd.tabulate(conditions=['English', 'German_Deutsch'],samples=range(10), cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven','and', 'the', 'earth', '.']\n",
    "\n",
    "bigrms = nltk.bigrams(sent)\n",
    "\n",
    "print(list(bigrms)) #need to convert to list to make iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b606011",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.corpus.genesis.words('english-kjv.txt')\n",
    "bigrams = nltk.bigrams(text)\n",
    "cfd = nltk.ConditionalFreqDist(bigrams)\n",
    "\n",
    "print(list(cfd['living']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781ced47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(cfdist,word,num=15):\n",
    "    for i in range(num):\n",
    "        print(word,end=\" \")\n",
    "        word = cfdist[word].max()\n",
    "\n",
    "generate_model(cfd,'living')  \n",
    "#the function definition had some minor errors in the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b4fab9",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "Suppose that you work on analyzing text that involves different forms of the same word, and that part of your program needs to work out the plural form of a given singular noun. Suppose it needs to do this work in two places, once when it is processing some texts and again when it is processing user input.\n",
    "\n",
    "Rather than repeating the same code several times over, it is more efficient and reliable to localize this work inside a function. A function is just a named block of code that performs some well-defined task, as we saw in Computing with Language: Texts and Words. A function is usually defined to take some inputs, using special variables known as parameters, and it may produce a result, also known as a return value. We define a function using the keyword def followed by the function name and any input parameters, followed by the body of the function. Here’s the function we saw in Computing with Language: Texts and Words (including the import statement that makes division behave as expected):\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    ">>> from __future__ import division<br>\n",
    ">>> def lexical_diversity(text):<br>\n",
    "...     return len(text) / len(set(text))<br>\n",
    "</div>\n",
    "\n",
    "We use the keyword return to indicate the value that is produced as output by the function. In this example, all the work of the function is done in the return statement. Here’s an equivalent definition that does the same work using multiple lines of code. We’ll change the parameter name from text to my_text_data to remind you that this is an arbitrary choice:\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    ">>> def lexical_diversity(my_text_data):<br>\n",
    "...     word_count = len(my_text_data)<br>\n",
    "...     vocab_size = len(set(my_text_data))<br>\n",
    "...     diversity_score = word_count / vocab_size<br>\n",
    "...     return diversity_score<br>\n",
    "</div>\n",
    "\n",
    "Notice that we’ve created some new variables inside the body of the function. These are local variables and are not accessible outside the function. So now we have defined a function with the name lexical_diversity. But just defining it won’t produce any output! Functions do nothing until they are “called” (or “invoked”).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5d701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plural(word):\n",
    "    if word.endswith('y'):\n",
    "        return word[:-1] + 'ies'\n",
    "    elif word[-1] in 'sx' or word[-2:] in ['sh', 'ch']:\n",
    "        return word + 'es'\n",
    "    elif word.endswith('an'):\n",
    "        return word[:-2] + 'en'\n",
    "    else:\n",
    "        return word + 's'\n",
    "    \n",
    "print(plural('fairy'))\n",
    "print(plural('woman'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d9c137",
   "metadata": {},
   "source": [
    "### Modules\n",
    "​\n",
    "Over time you will find that you create a variety of useful little text-processing functions, and you end up copying them from old programs to new ones. Which file contains the latest version of the function you want to use? It makes life a lot easier if you can collect your work into a single place, and access previously defined functions without making copies.\n",
    "​\n",
    "To do this, save your function(s) in a file called (say) textproc.py. Now, you can access your work simply by importing it from the file:\n",
    "​\n",
    "<div class=\"alert alert-block alert-info\">    \n",
    ">>> from textproc import plural<br>\n",
    ">>> plural('wish')<br>\n",
    "wishes<br>\n",
    ">>> plural('fan')<br>\n",
    "fen<br>\n",
    "</div>\n",
    "​\n",
    "Our plural function obviously has an error, since the plural of fan is fans. Instead of typing in a new version of the function, we can simply edit the existing one. Thus, at every stage, there is only one version of our plural function, and no confusion about which one is being used.\n",
    "​\n",
    "A collection of variable and function definitions in a file is called a Python module. A collection of related modules is called a package. NLTK’s code for processing the Brown Corpus is an example of a module, and its collection of code for processing all the different corpora is an example of a package. NLTK itself is a set of packages, sometimes called a library.\n",
    "​\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Caution!</b><br>\n",
    "​\n",
    "If you are creating a file to contain some of your Python code, do not name your file nltk.py: it may get imported in place of the “real” NLTK package. When it imports modules, Python first looks in the current directory (folder).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2846cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unusual_words(text):\n",
    "    text_vocab = set(w.lower() for w in text if w.isalpha())\n",
    "    english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
    "    unusual = text_vocab.difference(english_vocab)\n",
    "    return sorted(unusual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "unusual_words(nltk.corpus.gutenberg.words('austen-sense.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376b0f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unusual_words(nltk.corpus.nps_chat.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c06f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc3d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_fraction(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    content = [w for w in text if w.lower() not in stopwords]\n",
    "    return len(content) / len(text)\n",
    "\n",
    "content_fraction(nltk.corpus.reuters.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad778d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzle_letters = nltk.FreqDist('egivrvonl')\n",
    "obligatory = 'r'\n",
    "wordlist = nltk.corpus.words.words()\n",
    "[w for w in wordlist if len(w) >= 6 and obligatory in w and nltk.FreqDist(w) <= puzzle_letters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6553bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = nltk.corpus.names\n",
    "names.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c650f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_names = names.words('male.txt')\n",
    ">>> female_names = names.words('female.txt')\n",
    ">>> [w for w in male_names if w in female_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (fileid, name[-1])\n",
    "    for fileid in names.fileids()\n",
    "    for name in names.words(fileid))\n",
    "\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80de6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = nltk.corpus.cmudict.entries()\n",
    "len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267cfdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in entries[39943:39951]:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, pron in entries:\n",
    "    if len(pron) == 3:\n",
    "        ph1, ph2, ph3 = pron\n",
    "        if ph1 == 'P' and ph3 == 'T':\n",
    "            print (word, ph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a1812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable = ['N', 'IH0', 'K', 'S']\n",
    "[word for word, pron in entries if pron[-4:] == syllable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "[w for w, pron in entries if pron[-1] == 'M' and w[-1] == 'n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0582f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(set(w[:2] for w, pron in entries if pron[0] == 'N' and w[0] != 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d012bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stress(pron):\n",
    "    return [char for phone in pron for char in phone if char.isdigit()]\n",
    "[w for w, pron in entries if stress(pron) == ['0', '1', '0', '2', '0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f96d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[w for w, pron in entries if stress(pron) == ['0', '2', '0', '1', '0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81356f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = [(pron[0]+'-'+pron[2], word)\n",
    "    for (word, pron) in entries\n",
    "    if pron[0] == 'P' and len(pron) == 3]\n",
    "cfd = nltk.ConditionalFreqDist(p3)\n",
    "#cfd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd05b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for template in cfd.conditions():\n",
    "    if len(cfd[template]) > 10:\n",
    "        words = cfd[template].keys()\n",
    "        wordlist = ' '.join(words)\n",
    "        print(template, wordlist[:70] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prondict = nltk.corpus.cmudict.dict()\n",
    "prondict['fire'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prondict['blog'] \n",
    "#error exxample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fcaceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['natural', 'language', 'processing']\n",
    "[ph for w in text for ph in prondict[w][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import swadesh \n",
    "\n",
    "print(swadesh.fileids())\n",
    "print('next')\n",
    "print(swadesh.words('en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr2en = swadesh.entries(['fr', 'en'])\n",
    "fr2en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2006411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate = dict(fr2en)\n",
    "translate['chien']\n",
    "#translate['jeter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b1fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "de2en = swadesh.entries(['de', 'en'])    # German-English<br>\n",
    "es2en = swadesh.entries(['es', 'en'])    # Spanish-English<br>\n",
    "translate.update(dict(de2en))\n",
    "translate.update(dict(es2en))\n",
    "translate['Hund']\n",
    "#translate['perro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf44794",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['en', 'de', 'nl', 'es', 'fr', 'pt', 'la']\n",
    "for i in [139, 140, 141, 142]:\n",
    "    print(swadesh.entries(languages)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e75db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import toolbox\n",
    "toolbox.entries('rotokas.dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a9a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('motorcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a751293",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('car.n.01').lemma_names() #error in text, improper method call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b59c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('car.n.01').definition() #error in text, improper method call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d4627",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('car.n.01').examples() #error in text, improper method call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e108e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('car.n.01').lemmas() #error in text, improper method call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687818dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.lemma('car.n.01.automobile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dbf080",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.lemma('car.n.01.automobile').synset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14eecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.lemma('car.n.01.automobile').name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e161dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synsets('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a04bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for synset in wn.synsets('car'):\n",
    "    print(synset.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8bd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.lemmas('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedcace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "motorcar = wn.synset('car.n.01')\n",
    "motorcar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6545315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "types_of_motorcar = motorcar.hyponyms()\n",
    "types_of_motorcar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d1755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "types_of_motorcar[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6af2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#synset.name()\n",
    "#synset.lemmas()\n",
    "sorted([synset.name() for synset in types_of_motorcar for lemma in synset.lemmas()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d438f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "motorcar.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6133dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = motorcar.hypernym_paths()\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb0af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[synset.name() for synset in paths[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e919d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[synset.name() for synset in paths[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ec94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "motorcar.root_hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ba9308",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('tree.n.01').part_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('tree.n.01').substance_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be61e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('tree.n.01').member_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e74f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for synset in wn.synsets('mint', wn.NOUN):\n",
    "    print(synset.name() + ':', synset.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fd3a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('mint.n.04').part_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f764c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('mint.n.04').substance_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2182421",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('walk.v.01').entailments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d187b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('eat.v.01').entailments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbad204",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('tease.v.03').entailments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d4aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.lemma('supply.n.02.supply').antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026199bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.lemma('rush.v.01.rush').antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc4789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.lemma('horizontal.a.01.horizontal').antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d42a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.lemma('staccato.r.01.staccato').antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf62dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "right = wn.synset('right_whale.n.01')\n",
    "orca = wn.synset('orca.n.01')\n",
    "minke = wn.synset('minke_whale.n.01')\n",
    "tortoise = wn.synset('tortoise.n.01')\n",
    "novel = wn.synset('novel.n.01')\n",
    "print(right.lowest_common_hypernyms(minke))\n",
    "print(right.lowest_common_hypernyms(orca))\n",
    "print(right.lowest_common_hypernyms(tortoise))\n",
    "print(right.lowest_common_hypernyms(novel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91c365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wn.synset('baleen_whale.n.01').min_depth())\n",
    "print(wn.synset('whale.n.02').min_depth())\n",
    "print(wn.synset('vertebrate.n.01').min_depth())\n",
    "print(wn.synset('entity.n.01').min_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bca9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(right.path_similarity(minke))\n",
    "print(right.path_similarity(orca))\n",
    "print(right.path_similarity(tortoise))\n",
    "print(right.path_similarity(novel))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
